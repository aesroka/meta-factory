# v1.0 Status — How Close Are We?

**Short answer: very close.** The pipeline runs end-to-end; the only blocker is environment (API keys for the providers your Router uses). With at least one working provider that covers tier2 and tier3 (e.g. OpenAI), a full run completes.

## What’s done

| Area | Status |
|------|--------|
| **Greenfield pipeline** | Discovery → Architect → Estimator → Synthesis → Proposal runs; quality/hourly_rate threaded; critic feedback injected into retries; token usage (critic) fixed. |
| **Phased delivery** | Proposal and Synthesis prompts ask for `delivery_phases`, `recommended_first_phase`, and phase-level goals/success_criteria/`can_stop_here`. Contracts and CLI support it. |
| **Hourly rate** | `--hourly-rate` flows from CLI → EngagementManager → all swarms → ProposalInput; proposal agent can set `estimated_cost_gbp` in phases. |
| **Brownfield / Greyfield** | Both run with optional dossier; hourly_rate wired into proposal. |
| **Hybrid ingestion** | When RAG returns nothing, hybrid mode uses full-context dossier only (no crash). |
| **Ensemble estimation** | Cost limit checked between optimist/pessimist/realist runs; PERT aggregator tests pass. |
| **Showcase** | `scripts/showcase_forge_stream.py --dry-run` passes. |
| **Tests** | 121/122 tests pass. One known env-dependent failure: `test_rag_client.py::test_client_requires_api_key_for_availability`. |

## What you need for a successful run

1. **API keys**  
   At least one provider used by your Router must have a valid key.  
   - `python main.py --list-providers` shows which are ready.  
   - Tier3 (synthesis, proposal) uses the first model in the tier list that works; if the Router tries a provider without a key (e.g. Anthropic when you only have OpenAI), the run can fail with 401.  
   - **Practical v1.0 setup:** Ensure the first model in each tier (in `providers/router.py`) is a provider you have a key for (e.g. OpenAI for tier1/tier2/tier3), or set keys for the providers that are first in the list.

2. **E2E check**  
   ```bash
   python main.py --input ./workspace/sample_transcript.txt --client "Acme" --quality standard
   ```  
   With valid keys, this should produce a proposal (with delivery phases when the model follows the prompt) in a few minutes.

## Launch checklist (from docs/LAUNCH.md)

- [ ] **Standard run** — `--quality standard` produces a phased proposal in under 5 minutes *(depends on LLM speed and keys)*.
- [ ] **Premium run** — `--quality premium` uses ensemble + hybrid context *(code path is there; premium needs ingestion/dossier for full hybrid)*.
- [ ] **Proposal shape** — At least 2 delivery phases, first phase ≤6 weeks *(prompts ask for it; model-dependent)*.
- [ ] **Hybrid reconciliation** — Implemented; RAG=None fallback fixed.
- [ ] **Ensemble range** — PERT math and cost-limit between runs done.
- [ ] **Three modes** — Greenfield, brownfield, greyfield run with hourly_rate.
- [ ] **Tier routing** — tier0/tier1/tier2/tier3 wired.
- [ ] **Cost and hourly-rate** — Tracked and passed through.
- [ ] **pytest** — 121 pass; 1 known failure (RAG client env).
- [ ] **README** — Quick start and quality tiers documented.
- [ ] **Output** — Proposal structure supports phased delivery.

## Recommended next steps to “v1.0 and working”

1. **Run with your keys**  
   Set `OPENAI_API_KEY` (and/or others) so `--list-providers` shows at least one ready. Run the E2E command above and confirm a proposal is written.

2. **Optional: single-provider Router**  
   If you want v1.0 to work with only OpenAI, put OpenAI models first (and only) for each tier in `providers/router.py` so the Router never calls a provider without a key.

3. **Optional: mark RAG test as skip**  
   In `tests/test_rag_client.py`, skip `test_client_requires_api_key_for_availability` when `RAGFLOW_API_KEY` is unset (or mark as `@pytest.mark.env`), so `pytest` is fully green for normal dev.

4. **Ship**  
   Tag v1.0 and document in README that users need at least one LLM provider configured and, for premium, optional RAGFlow for hybrid context.
